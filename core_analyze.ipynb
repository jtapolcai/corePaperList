{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "882cb5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Downloading version: CORE2008\n",
      "‚ùå Error fetching CORE2008 page 7: 500\n",
      "‚úÖ Saved: core_C_CORE2008_export.csv\n",
      "‚ñ∂Ô∏è Downloading version: CORE2013\n",
      "‚ùå Error fetching CORE2013 page 18: 500\n",
      "‚úÖ Saved: core_C_CORE2013_export.csv\n",
      "‚ñ∂Ô∏è Downloading version: CORE2014\n",
      "‚ùå Error fetching CORE2014 page 18: 500\n",
      "‚úÖ Saved: core_C_CORE2014_export.csv\n",
      "‚ñ∂Ô∏è Downloading version: CORE2017\n",
      "‚ùå Error fetching CORE2017 page 17: 500\n",
      "‚úÖ Saved: core_C_CORE2017_export.csv\n",
      "‚ñ∂Ô∏è Downloading version: CORE2018\n",
      "‚ùå Error fetching CORE2018 page 17: 500\n",
      "‚úÖ Saved: core_C_CORE2018_export.csv\n",
      "‚ñ∂Ô∏è Downloading version: CORE2020\n",
      "‚ùå Error fetching CORE2020 page 6: 500\n",
      "‚úÖ Saved: core_C_CORE2020_export.csv\n",
      "‚ñ∂Ô∏è Downloading version: CORE2021\n",
      "‚ùå Error fetching CORE2021 page 7: 500\n",
      "‚úÖ Saved: core_C_CORE2021_export.csv\n",
      "‚ñ∂Ô∏è Downloading version: CORE2023\n",
      "‚ùå Error fetching CORE2023 page 9: 500\n",
      "‚úÖ Saved: core_C_CORE2023_export.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "rank=\"A*\"\n",
    "rank=\"A\"\n",
    "rank=\"B\"\n",
    "rank=\"C\"\n",
    "\n",
    "rank_name=rank.replace(\"*\",\"star\")\n",
    "\n",
    "core_versions = [\"CORE2008\", \"CORE2013\", \"CORE2014\", \"CORE2017\", \"CORE2018\", \"CORE2020\", \"CORE2021\", \"CORE2023\"]\n",
    "url = \"https://portal.core.edu.au/conf-ranks/\"\n",
    "\n",
    "for core in core_versions:\n",
    "    print(\"‚ñ∂Ô∏è Downloading version: {}\".format(core))\n",
    "    page = 1\n",
    "    all_rows = []\n",
    "    header_saved = False\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"search\": rank,\n",
    "            \"by\": \"rank\",\n",
    "            \"source\": core,\n",
    "            \"sort\": \"asource\",\n",
    "            \"page\": page,\n",
    "            \"do\": \"Export\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            csv_data = response.content.decode(\"utf-8\")\n",
    "            csv_reader = csv.reader(StringIO(csv_data))\n",
    "            rows = list(csv_reader)\n",
    "\n",
    "            if not rows or len(rows) <= 1:\n",
    "                break  # No data\n",
    "\n",
    "            if not header_saved:\n",
    "                all_rows.append(rows[0])\n",
    "                header_saved = True\n",
    "\n",
    "            all_rows.extend(rows[1:])\n",
    "\n",
    "            if len(rows) < 51:\n",
    "                break  # Last page\n",
    "            page += 1\n",
    "        else:\n",
    "            print(\"Could not fetch {} page {}: response was {}\".format(core, page, response.status_code))\n",
    "            break\n",
    "\n",
    "    filename = \"core_{}_{}_export.csv\".format(rank_name,core)\n",
    "    with open(filename, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(all_rows)\n",
    "    print(\"‚úÖ Saved: {}\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b49a9276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Feldolgoz√°s: 1. oldal...\n",
      "üîÑ Feldolgoz√°s: 2. oldal...\n",
      "üîÑ Feldolgoz√°s: 3. oldal...\n",
      "üîÑ Feldolgoz√°s: 4. oldal...\n",
      "üîÑ Feldolgoz√°s: 5. oldal...\n",
      "üîÑ Feldolgoz√°s: 6. oldal...\n",
      "üîÑ Feldolgoz√°s: 7. oldal...\n",
      "üîÑ Feldolgoz√°s: 8. oldal...\n",
      "üîÑ Feldolgoz√°s: 9. oldal...\n",
      "üîÑ Feldolgoz√°s: 10. oldal...\n",
      "üîÑ Feldolgoz√°s: 11. oldal...\n",
      "üîÑ Feldolgoz√°s: 12. oldal...\n",
      "üîÑ Feldolgoz√°s: 13. oldal...\n",
      "üîÑ Feldolgoz√°s: 14. oldal...\n",
      "üîÑ Feldolgoz√°s: 15. oldal...\n",
      "üîÑ Feldolgoz√°s: 16. oldal...\n",
      "üîÑ Feldolgoz√°s: 17. oldal...\n",
      "üîÑ Feldolgoz√°s: 18. oldal...\n",
      "üîÑ Feldolgoz√°s: 19. oldal...\n",
      "üîÑ Feldolgoz√°s: 20. oldal...\n",
      "üîÑ Feldolgoz√°s: 21. oldal...\n",
      "üîÑ Feldolgoz√°s: 22. oldal...\n",
      "‚úÖ Utols√≥ oldal el√©rve.\n",
      "‚úÖ Ment√©s k√©sz: core_C_with_dblp.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "BASE_URL = \"https://portal.core.edu.au/conf-ranks/\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "all_rows = []\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"üîÑ Feldolgoz√°s: {page}. oldal...\")\n",
    "    params = {\n",
    "        \"search\": rank,\n",
    "        \"by\": \"rank\",\n",
    "        \"source\": \"all\",\n",
    "        \"sort\": \"asource\",\n",
    "        \"page\": page\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    table = soup.find(\"table\")\n",
    "    if not table:\n",
    "        print(\"üö´ Nem tal√°lhat√≥ t√°bl√°zat ezen az oldalon.\")\n",
    "        break\n",
    "\n",
    "    rows = table.find_all(\"tr\")[1:]  # Skip header\n",
    "    if not rows or len(rows) < 50:\n",
    "        print(\"‚úÖ Utols√≥ oldal el√©rve.\")\n",
    "        break\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) != 9:\n",
    "            continue\n",
    "\n",
    "        title = cols[0].text.strip()\n",
    "        acronym = cols[1].text.strip()\n",
    "        source = cols[2].text.strip()\n",
    "        rank = cols[3].text.strip()\n",
    "        note = cols[4].text.strip()\n",
    "        dblp_tag = cols[5].find(\"a\")\n",
    "        dblp = dblp_tag[\"href\"].strip() if dblp_tag else \"\"\n",
    "        primary_for = cols[6].text.strip()\n",
    "        comments = cols[7].text.strip()\n",
    "        avg_rating = cols[8].text.strip()\n",
    "\n",
    "        all_rows.append([\n",
    "            title, acronym, source, rank, note,\n",
    "            dblp, primary_for, comments, avg_rating\n",
    "        ])\n",
    "\n",
    "    page += 1\n",
    "\n",
    "# CSV ment√©s\n",
    "filename = \"core_{}_with_dblp.csv\".format(rank_name)\n",
    "with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\n",
    "        \"Title\", \"Acronym\", \"Source\", \"Rank\", \"Note\",\n",
    "        \"DBLP\", \"Primary FoR\", \"Comments\", \"Average Rating\"\n",
    "    ])\n",
    "    writer.writerows(all_rows)\n",
    "\n",
    "print(\"‚úÖ Ment√©s k√©sz: {}\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a53d93b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Elmentve: core_C_merged_5cols_by_acronym.csv\n",
      "‚úÖ Elmentve: core_C_conferences.json with 1004 records\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "# üìÅ Be√°ll√≠t√°sok\n",
    "directory = \"./\"\n",
    "csv_files = glob.glob(os.path.join(directory, \"core_{}_*_export.csv\".format(rank_name)))\n",
    "dblp_file = \"core_{}_with_dblp.csv\".format(rank_name)\n",
    "\n",
    "# üîÑ √öj strukt√∫ra: Acronym alapj√°n\n",
    "acronym_to_info = {}\n",
    "\n",
    "# üîÑ CSV f√°jlok feldolgoz√°sa\n",
    "for file in csv_files:\n",
    "    year = os.path.basename(file).split(\"_\")[2]\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df.columns.values[0] = \"ID\"\n",
    "    df.columns.values[1] = \"Name\"\n",
    "    df.columns.values[2] = \"Acronym\"\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        acronym = row[\"Acronym\"]\n",
    "        if pd.isna(acronym):\n",
    "            continue  # üõë Skip rows with missing acronyms\n",
    "        if acronym not in acronym_to_info:\n",
    "            acronym_to_info[acronym] = {\n",
    "                \"Acronym\": acronym,\n",
    "                \"Name\": row[\"Name\"],\n",
    "                \"YearsListed\": [year],\n",
    "                \"DBLP ID\": row[\"ID\"]\n",
    "            }\n",
    "        else:\n",
    "            if year not in acronym_to_info[acronym][\"YearsListed\"]: \n",
    "                acronym_to_info[acronym][\"YearsListed\"].append(year)\n",
    "\n",
    "# üì• DBLP f√°jl beolvas√°sa\n",
    "dblp_df = pd.read_csv(dblp_file)\n",
    "if \"Acronym\" not in dblp_df.columns or \"DBLP\" not in dblp_df.columns:\n",
    "    raise KeyError(\"Acronym vagy DBLP oszlop hi√°nyzik a DBLP f√°jlb√≥l.\")\n",
    "\n",
    "# üîó DBLP linkek hozz√°ad√°sa a dictionary-hez\n",
    "for _, row in dblp_df.iterrows():\n",
    "    acronym = row[\"Acronym\"]\n",
    "    if acronym in acronym_to_info:\n",
    "        acronym_to_info[acronym][\"DBLP URL\"] = row[\"DBLP\"]\n",
    "        acronym_to_info[acronym][\"Average Rating\"] = str(row.get(\"Average Rating\", None))\n",
    "\n",
    "# üßæ T√°bl√°zat √©p√≠t√©se\n",
    "final_df = pd.DataFrame(acronym_to_info.values())\n",
    "final_df[\"YearsListed\"] = final_df[\"YearsListed\"].apply(lambda y: \", \".join(sorted(y)))\n",
    "\n",
    "# üíæ Ment√©s\n",
    "final_df.to_csv(\"core_{}_merged_5cols_by_acronym.csv\".format(rank_name), index=False)\n",
    "print(\"‚úÖ Elmentve: core_{}_merged_5cols_by_acronym.csv\".format(rank_name))\n",
    "\n",
    "# üìÖ Intervallum hozz√°ad√°sa, 2008 √©s 2023 elhagy√°s√°val\n",
    "# üìÖ Intervallum hozz√°ad√°sa, 2008 √©s 2023 elhagy√°s√°val\n",
    "all_years_int = set()\n",
    "for conf in acronym_to_info.values():\n",
    "    all_years_int.update(int(y.replace(\"CORE\", \"\")) for y in conf[\"YearsListed\"])\n",
    "year_min = min(all_years_int)\n",
    "year_max = max(all_years_int)\n",
    "\n",
    "for conf in acronym_to_info.values():\n",
    "    years = sorted(int(y.replace(\"CORE\", \"\")) for y in conf[\"YearsListed\"])\n",
    "    start = min(years)\n",
    "    end = max(years)\n",
    "\n",
    "    if start == year_min and end == year_max:\n",
    "        conf[\"YearsInterval\"] = \"\"\n",
    "    elif start == year_min:\n",
    "        conf[\"YearsInterval\"] = f\"‚Äì{end}\"\n",
    "    elif end == year_max:\n",
    "        conf[\"YearsInterval\"] = f\"{start}‚Äì\"\n",
    "    else:\n",
    "        conf[\"YearsInterval\"] = f\"{start}‚Äì{end}\"\n",
    "    \n",
    "\n",
    "with open(\"core_{}_conferences.json\".format(rank_name), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(acronym_to_info, f, indent=2, ensure_ascii=False)\n",
    "print(\"‚úÖ Elmentve: core_{}_conferences.json with {} records\".format(rank_name, len(acronym_to_info)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c8044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è Astar konferenci√°k sz√°ma: 80 (normalized: 1.0) az utols√≥ban 59 (nromalized: 1.0)\n",
      "üè∑Ô∏è A konferenci√°k sz√°ma: 327 (normalized: 4.0875) az utols√≥ban 116 (nromalized: 1.9661016949152543)\n",
      "üè∑Ô∏è B konferenci√°k sz√°ma: 621 (normalized: 7.7625) az utols√≥ban 220 (nromalized: 3.7288135593220337)\n",
      "üè∑Ô∏è C konferenci√°k sz√°ma: 1004 (normalized: 12.55) az utols√≥ban 357 (nromalized: 6.0508474576271185)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "normalize=0\n",
    "normalize_all=0\n",
    "for rank in [\"Astar\",\"A\",\"B\",\"C\"]:\n",
    "    try:\n",
    "        with open(f'core_{rank}_conferences_classified.json', 'r', encoding='utf-8') as f:\n",
    "            conferences = json.load(f)\n",
    "\n",
    "        in_last_core = 0\n",
    "        for acronym, info in conferences.items():\n",
    "            if \"CORE2023\" in info.get(\"YearsListed\", []):\n",
    "                in_last_core += 1\n",
    "        if normalize==0:\n",
    "            normalize=in_last_core\n",
    "        if normalize_all==0:\n",
    "            normalize_all=len(conferences)\n",
    "        print(f\"üè∑Ô∏è {rank} konferenci√°k sz√°ma: {len(conferences)} (normalized: {len(conferences)/normalize_all}) az utols√≥ban {in_last_core} (normalized: {in_last_core/normalize})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üö´ Hiba a {rank} f√°jl feldolgoz√°sakor: {e}\")\n",
    "\n",
    "        old_name = f\"core_{rank}_conferences.json\"\n",
    "        new_name = f\"core_{rank}_conferences_classified.json\"\n",
    "\n",
    "        # use notebook-level flags if present\n",
    "        force = globals().get(\"force\", False)\n",
    "        dry_run = globals().get(\"dry_run\", False)\n",
    "\n",
    "        if not os.path.exists(old_name):\n",
    "            print(f\"[skip] {old_name} not found\")\n",
    "            continue\n",
    "\n",
    "        if os.path.exists(new_name) and not force:\n",
    "            print(f\"[exists] {new_name} already exists (set force=True to overwrite)\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Renaming: {old_name} -> {new_name}\")\n",
    "        if not dry_run:\n",
    "            if os.path.exists(new_name) and force:\n",
    "                os.remove(new_name)\n",
    "            os.rename(old_name, new_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
